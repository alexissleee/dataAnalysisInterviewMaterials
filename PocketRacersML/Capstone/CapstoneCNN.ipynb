{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NemH8ov41giJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras import Model # if only machine learning were this easy :P\n",
        "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization, Dropout\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "#import any other libraries you want here:\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "from skimage.io import imread, imshow, imsave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUOQw5A77M9y",
        "outputId": "42144280-896b-44f5-f767-c78962c61b04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/My Drive/Extracurriculars/IEEE/PocketRacers/dataset.csv')\n",
        "df = df.sample(frac=1, random_state = 0).reset_index(drop=True)\n",
        "\n",
        "x = df['transformed_file_name'].values\n",
        "y = df['class_indices'].values\n",
        "\n",
        "new_x = []\n",
        "for i in range(len(x)):\n",
        "  im = imread(x[i])\n",
        "  new_x.append(im)\n",
        "\n",
        "x = new_x\n",
        "x = np.array(x)\n",
        "# Let's grab some validation data from our training dataset!\n",
        "# 5000 datapoints should be enough.\n",
        "# Remember to remove them from your training data!\n",
        "x_val = x[:300] #any 5000 points from x_train\n",
        "y_val = y[:300] #same 5000 points from y_train\n",
        "\n",
        "x_train = x[300:] #x_train - x_val\n",
        "y_train = y[300:] #y_train - y_val\n",
        "\n",
        "# This stuff will throw an error until the above is completed.\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2c_v8R3R-Z",
        "outputId": "a534f0e3-0d38-4ed5-fe80-f17a8b130cc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 480, 640, 3)\n",
            "(1200,)\n",
            "(300, 480, 640, 3)\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train[0].shape\n",
        "\n",
        "# First, we declare the size of our inputs\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# YOUR TURN:\n",
        "# This is where our layers go. Add/modify the layers of your\n",
        "# neural network here.\n",
        "# Note the basic syntax for defining this network. Each layer\n",
        "# is defined by calling a function on the layer before; the functions\n",
        "# themselves and their parameters are outlined in the tf.keras docs\n",
        "\n",
        "#You should customize and experiment with your architecture, but if you want\n",
        "#a (somewhat arbitrary) place to start, try the following:\n",
        "    # 5x5 convolutional layer with 10 output channels\n",
        "    # maxpool 2\n",
        "    # 3x3 convolution with 20 output channels\n",
        "    # Batchnorm\n",
        "    # Maxpool 2\n",
        "    # Flatten\n",
        "    # Dropout = 0.5\n",
        "    # FC layers with 128 neurons\n",
        "    # Batchnorm\n",
        "    # FC layers with 10 neurons\n",
        "\n",
        "\n",
        "x = Conv2D(10, (5, 5))(inputs) # 5x5 convolutional layer with 10 output channels\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x) # maxpool 2\n",
        "x = Conv2D(20, kernel_size=(3, 3))(x) # 3x3 convolution with 20 output channels\n",
        "x = BatchNormalization()(x) # Batchnorm\n",
        "x = Flatten()(x) # Flatten\n",
        "x = Dropout(0.5)(x) # dropout = 0.5\n",
        "x = Dense(128)(x) # FC layers with 128 neurons\n",
        "x = BatchNormalization()(x) # Batchnorm\n",
        "x = Dense(10)(x) # FC layers with 10 neurons\n",
        "\n",
        "# Make sure there are 10 outputs!\n",
        "x = Dense(10)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "#Select an appropriate keras optimizer and adjust its parameters: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "# use Adam\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.00006,\n",
        "    weight_decay=0.0001,\n",
        ")\n",
        "\n",
        "#Select an appropriate keras loss function. remember to set from_logits=True if your model does not pass your outputs\n",
        "#through a softmax function: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "# sparse categorical cross entropy loss\n",
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        ")\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss=loss_func,\n",
        "              metrics=['accuracy'] #metrics tells the model what to print while we are training. We would like to see the accuracy\n",
        "              )"
      ],
      "metadata": {
        "id": "VtxGlRG53IqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "btfTU8yKBSL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Riv3S0gUUGFA",
        "outputId": "77a120ca-9893-4804-9c0f-bd5c5668aec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 19s 253ms/step - loss: 0.0893 - accuracy: 0.9750 - val_loss: 3.7120 - val_accuracy: 0.6900\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 7s 181ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.4693 - val_accuracy: 0.8767\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 7s 185ms/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.0581 - val_accuracy: 0.9733\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 7s 181ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 7s 185ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 7s 180ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 7s 186ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 7s 182ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 7s 192ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 7s 189ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 7s 188ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 9.4841e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 7s 191ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 8.5708e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 7s 196ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.4461e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 7s 194ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.8124e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 7s 189ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.1856e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 7s 191ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.1352e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 7s 189ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.0345e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 7s 192ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4981e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 7s 186ms/step - loss: 9.7203e-04 - accuracy: 1.0000 - val_loss: 4.2149e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 7s 191ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.9157e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(x_val, y_val)\n",
        "print(val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F75Y94yPWPDN",
        "outputId": "b14eb5ed-c1fb-4ae2-e601-efa59333dad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 51ms/step - loss: 3.9157e-04 - accuracy: 1.0000\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put the collected data here as test data"
      ],
      "metadata": {
        "id": "evzQZTcuW2u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('drive/My Drive/Extracurriculars/IEEE/PocketRacers/cnn_model.h5')"
      ],
      "metadata": {
        "id": "WgSelU6HvHfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('drive/My Drive/Extracurriculars/IEEE/PocketRacers/cnn_model.h5')"
      ],
      "metadata": {
        "id": "8ZiUh1ZZxVfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
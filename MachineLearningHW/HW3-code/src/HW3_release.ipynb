{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H420KxmCjKH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To add your own Drive Run this cell.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BCDUFCh7Fd-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df85ec98-7557-4a44-a1fc-770bae7ed4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please append your own directory after â€˜/content/drive/My Drive/'\n",
        "### ========== TODO : START ========== ###\n",
        "sys.path += ['/content/drive/My Drive/Academics/2023-2024/EC_ENGR_M146/HW3-code']\n",
        "### ========== TODO : END ========== ###"
      ],
      "metadata": {
        "id": "nQXiXrbaF3NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Author      : Yi-Chieh Wu, Sriram Sankararman\n",
        "Description : Twitter\n",
        "\"\"\"\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# !!! MAKE SURE TO USE LinearSVC.decision_function(X), NOT LinearSVC.predict(X) !!!\n",
        "# (this makes ''continuous-valued'' predictions)\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "7_OLupUPC2U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3: Twitter Analysis Using SVM"
      ],
      "metadata": {
        "id": "47L2XVzBX6c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# functions -- input/output\n",
        "######################################################################\n",
        "\n",
        "def read_vector_file(fname):\n",
        "    \"\"\"\n",
        "    Reads and returns a vector from a file.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        fname  -- string, filename\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        labels -- numpy array of shape (n,)\n",
        "                    n is the number of non-blank lines in the text file\n",
        "    \"\"\"\n",
        "    return np.genfromtxt(fname)\n",
        "\n",
        "\n",
        "def write_label_answer(vec, outfile):\n",
        "    \"\"\"\n",
        "    Writes your label vector to the given file.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        vec     -- numpy array of shape (n,) or (n,1), predicted scores\n",
        "        outfile -- string, output filename\n",
        "    \"\"\"\n",
        "\n",
        "    # for this project, you should predict 70 labels\n",
        "    if(vec.shape[0] != 70):\n",
        "        print(\"Error - output vector should have 70 rows.\")\n",
        "        print(\"Aborting write.\")\n",
        "        return\n",
        "\n",
        "    np.savetxt(outfile, vec)\n"
      ],
      "metadata": {
        "id": "9Z8E5YL0CzWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# functions -- feature extraction\n",
        "######################################################################\n",
        "\n",
        "def extract_words(input_string):\n",
        "    \"\"\"\n",
        "    Processes the input_string, separating it into \"words\" based on the presence\n",
        "    of spaces, and separating punctuation marks into their own words.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        input_string -- string of characters\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        words        -- list of lowercase \"words\"\n",
        "    \"\"\"\n",
        "\n",
        "    for c in punctuation :\n",
        "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
        "    return input_string.lower().split()\n",
        "\n",
        "\n",
        "def extract_dictionary(infile):\n",
        "    \"\"\"\n",
        "    Given a filename, reads the text file and builds a dictionary of unique\n",
        "    words/punctuations.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        infile    -- string, filename\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        word_list -- dictionary, (key, value) pairs are (word, index)\n",
        "    \"\"\"\n",
        "\n",
        "    word_list = {}\n",
        "    idx = 0\n",
        "    with open(infile, 'r') as fid :\n",
        "        # process each line to populate word_list\n",
        "        for input_string in fid:\n",
        "            words = extract_words(input_string)\n",
        "            for word in words:\n",
        "                if word not in word_list:\n",
        "                    word_list[word] = idx\n",
        "                    idx += 1\n",
        "    return word_list\n",
        "\n",
        "\n",
        "def extract_feature_vectors(infile, word_list):\n",
        "    \"\"\"\n",
        "    Produces a bag-of-words representation of a text file specified by the\n",
        "    filename infile based on the dictionary word_list.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        infile         -- string, filename\n",
        "        word_list      -- dictionary, (key, value) pairs are (word, index)\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        feature_matrix -- numpy array of shape (n,d)\n",
        "                          boolean (0,1) array indicating word presence in a string\n",
        "                            n is the number of non-blank lines in the text file\n",
        "                            d is the number of unique words in the text file\n",
        "    \"\"\"\n",
        "\n",
        "    num_lines = sum(1 for line in open(infile,'r'))\n",
        "    num_words = len(word_list)\n",
        "    feature_matrix = np.zeros((num_lines, num_words))\n",
        "\n",
        "    with open(infile, 'r') as fid :\n",
        "        # process each line to populate feature_matrix\n",
        "        for i, input_string in enumerate(fid):\n",
        "            words = extract_words(input_string)\n",
        "            for word in words:\n",
        "                feature_matrix[i, word_list[word]] = 1.0\n",
        "\n",
        "    return feature_matrix"
      ],
      "metadata": {
        "id": "i67aTAmrGGHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# functions -- evaluation\n",
        "######################################################################\n",
        "\n",
        "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Calculates the performance metric based on the agreement between the\n",
        "    true labels and the predicted labels.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        y_true -- numpy array of shape (n,), known labels\n",
        "        y_pred -- numpy array of shape (n,), (continuous-valued) predictions\n",
        "        metric -- string, option used to select the performance measure\n",
        "                  options: 'accuracy', 'f1-score', 'auroc', 'precision',\n",
        "                           'sensitivity', 'specificity'\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score  -- float, performance score\n",
        "    \"\"\"\n",
        "    # map continuous-valued predictions to binary labels\n",
        "    y_label = np.sign(y_pred)\n",
        "    y_label[y_label==0] = 1\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 1a: compute classifier performance\n",
        "    if (metric == \"accuracy\"):\n",
        "      return metrics.accuracy_score(y_true, y_pred)\n",
        "    elif (metric == \"f1-score\"):\n",
        "      return metrics.f1_score(y_true, y_pred)\n",
        "    elif (metric == \"auroc\"):\n",
        "      return metrics.roc_auc_score(y_true, y_pred)\n",
        "    elif (metric == \"precision\"):\n",
        "      return metrics.precision_score(y_true, y_pred)\n",
        "    elif (metric == \"sensitivity\"):\n",
        "      return metrics.recall_score(y_true, y_pred)\n",
        "    elif (metric == \"specificity\"):\n",
        "      tn, tp, fn, fp = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
        "      return tn / (tn + fp)\n",
        "    else:\n",
        "      return -1\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n",
        "    Trains classifier on k-1 folds and tests on the remaining fold.\n",
        "    Calculates the k-fold cross-validation performance metric for classifier\n",
        "    by averaging the performance across folds.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf    -- classifier (instance of LinearSVC)\n",
        "        X      -- numpy array of shape (n,d), feature vectors\n",
        "                    n = number of examples\n",
        "                    d = number of features\n",
        "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
        "        kf     -- model_selection.StratifiedKFold\n",
        "        metric -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score   -- float, average cross-validation performance across k folds\n",
        "    \"\"\"\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 1b: compute average cross-validation performance\n",
        "    score = 0\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "      X_train = X[train_index]\n",
        "      X_test = X[test_index]\n",
        "      y_train = y[train_index]\n",
        "      y_test = y[test_index]\n",
        "\n",
        "      clf.fit(X_train, y_train)\n",
        "      y_pred = clf.decision_function(X_test)\n",
        "      for index in range(len(y_pred)): # cuz confidence returns distances\n",
        "        if y_pred[index] < 0:\n",
        "          y_pred[index] = -1\n",
        "        else:\n",
        "          y_pred[index] = 1\n",
        "\n",
        "      score += performance(y_test, y_pred, metric)\n",
        "    score /= kf.n_splits\n",
        "\n",
        "    return score\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def select_param_linear(X, y, kf, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Sweeps different settings for the hyperparameter of a linear SVM,\n",
        "    calculating the k-fold CV performance for each setting, then selecting the\n",
        "    hyperparameter that 'maximize' the average k-fold CV performance.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        X      -- numpy array of shape (n,d), feature vectors\n",
        "                    n = number of examples\n",
        "                    d = number of features\n",
        "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
        "        kf     -- model_selection.StratifiedKFold\n",
        "        metric -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        C -- float, optimal parameter value for linear SVM\n",
        "    \"\"\"\n",
        "\n",
        "    print('Linear SVM Hyperparameter Selection based on ' + str(metric) + ':')\n",
        "    C_range = 10.0 ** np.arange(-3, 3)\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 1c: select optimal hyperparameter using cross-validation\n",
        "    performances = []\n",
        "    for C in C_range:\n",
        "      clf = LinearSVC(loss='hinge', random_state = 0, C = C)\n",
        "      performances.append(cv_performance(clf, X, y, kf, metric))\n",
        "\n",
        "    print(C_range[np.argmax(performances)])\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def performance_test(clf, X, y, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Estimates the performance of the classifier.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf          -- classifier (instance of LinearSVC)\n",
        "                          [already fit to data]\n",
        "        X            -- numpy array of shape (n,d), feature vectors of test set\n",
        "                          n = number of examples\n",
        "                          d = number of features\n",
        "        y            -- numpy array of shape (n,), binary labels {1,-1} of test set\n",
        "        metric       -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score        -- float, classifier performance\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 2b: return performance on test data under a metric.\n",
        "    print(\"metric: \", metric)\n",
        "    y_pred = clf.decision_function(X)\n",
        "    for index in range(len(y_pred)): # cuz confidence returns distances\n",
        "      if y_pred[index] < 0:\n",
        "        y_pred[index] = -1\n",
        "      else:\n",
        "        y_pred[index] = 1\n",
        "\n",
        "    print(\"performance: \", performance(y, y_pred, metric))\n",
        "    ### ========== TODO : END ========== ###"
      ],
      "metadata": {
        "id": "-MvTxQPRGOOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# main\n",
        "######################################################################\n",
        "\n",
        "def main() :\n",
        "    np.random.seed(1234)\n",
        "\n",
        "    # read the tweets and its labels, change the following two lines to your own path.\n",
        "    ### ========== TODO : START ========== ###\n",
        "    file_path = '/content/drive/My Drive/Academics/2023-2024/EC_ENGR_M146/HW3-code/data/tweets.txt'\n",
        "    label_path = '/content/drive/My Drive/Academics/2023-2024/EC_ENGR_M146/HW3-code/data/labels.txt'\n",
        "    ### ========== TODO : END ========== ###\n",
        "    dictionary = extract_dictionary(file_path)\n",
        "    print(len(dictionary))\n",
        "    X = extract_feature_vectors(file_path, dictionary)\n",
        "    y = read_vector_file(label_path)\n",
        "    # split data into training (training + cross-validation) and testing set\n",
        "    X_train, X_test = X[:560], X[560:]\n",
        "    y_train, y_test = y[:560], y[560:]\n",
        "\n",
        "    metric_list = [\"accuracy\", \"f1-score\", \"auroc\", \"precision\", \"sensitivity\", \"specificity\"]\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 1b: create stratified folds (5-fold CV)\n",
        "    kf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "    # part 1c: for each metric, select optimal hyperparameter for linear SVM using CV\n",
        "    for metric in metric_list:\n",
        "      select_param_linear(X, y, kf, metric)\n",
        "\n",
        "    # part 2a: train linear SVMs with selected hyperparameters\n",
        "    #accuracy\n",
        "    clf1 = LinearSVC(loss='hinge', random_state = 0, C = 1)\n",
        "    clf1.fit(X_train, y_train)\n",
        "\n",
        "    #f1-score\n",
        "    clf2 = LinearSVC(loss='hinge', random_state = 0, C = 1)\n",
        "    clf2.fit(X_train, y_train)\n",
        "\n",
        "    #auroc\n",
        "    clf3 = LinearSVC(loss='hinge', random_state = 0, C = 10)\n",
        "    clf3.fit(X_train, y_train)\n",
        "\n",
        "    #precision\n",
        "    clf4 = LinearSVC(loss='hinge', random_state = 0, C = 10)\n",
        "    clf4.fit(X_train, y_train)\n",
        "\n",
        "    #sensitivity\n",
        "    clf5 = LinearSVC(loss='hinge', random_state = 0, C = 0.001)\n",
        "    clf5.fit(X_train, y_train)\n",
        "\n",
        "    #specificity\n",
        "    clf6 = LinearSVC(loss='hinge', random_state = 0, C = 10)\n",
        "    clf6.fit(X_train, y_train)\n",
        "\n",
        "    # part 2b: test the performance of your classifiers.\n",
        "    # accuracy\n",
        "    performance_test(clf1, X_test, y_test, \"accuracy\")\n",
        "\n",
        "    #f1-score\n",
        "    performance_test(clf2, X_test, y_test, \"f1-score\")\n",
        "\n",
        "    #auroc\n",
        "    performance_test(clf3, X_test, y_test, \"auroc\")\n",
        "\n",
        "    #precision\n",
        "    performance_test(clf4, X_test, y_test, \"precision\")\n",
        "\n",
        "    #sensitivity\n",
        "    performance_test(clf5, X_test, y_test, \"sensitivity\")\n",
        "\n",
        "    #specificity\n",
        "    performance_test(clf6, X_test, y_test, \"specificity\")\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    main()"
      ],
      "metadata": {
        "id": "zMIQRGpYErVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f2daf8-8e24-440a-d026-ecf74d0e62e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1811\n",
            "Linear SVM Hyperparameter Selection based on accuracy:\n",
            "1.0\n",
            "Linear SVM Hyperparameter Selection based on f1-score:\n",
            "1.0\n",
            "Linear SVM Hyperparameter Selection based on auroc:\n",
            "10.0\n",
            "Linear SVM Hyperparameter Selection based on precision:\n",
            "10.0\n",
            "Linear SVM Hyperparameter Selection based on sensitivity:\n",
            "0.001\n",
            "Linear SVM Hyperparameter Selection based on specificity:\n",
            "10.0\n",
            "metric:  accuracy\n",
            "performance:  0.7428571428571429\n",
            "metric:  f1-score\n",
            "performance:  0.47058823529411764\n",
            "metric:  auroc\n",
            "performance:  0.6258503401360545\n",
            "metric:  precision\n",
            "performance:  0.6363636363636364\n",
            "metric:  sensitivity\n",
            "performance:  1.0\n",
            "metric:  specificity\n",
            "performance:  0.8653846153846154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5: Boosting vs. Decision Tree"
      ],
      "metadata": {
        "id": "_W-_mjX0JMes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ],
      "metadata": {
        "id": "0uzCdPTkOQSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data :\n",
        "\n",
        "    def __init__(self) :\n",
        "        \"\"\"\n",
        "        Data class.\n",
        "\n",
        "        Attributes\n",
        "        --------------------\n",
        "            X -- numpy array of shape (n,d), features\n",
        "            y -- numpy array of shape (n,), targets\n",
        "        \"\"\"\n",
        "\n",
        "        # n = number of examples, d = dimensionality\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "\n",
        "        self.Xnames = None\n",
        "        self.yname = None\n",
        "\n",
        "    def load(self, filename, header=0, predict_col=-1) :\n",
        "        \"\"\"Load csv file into X array of features and y array of labels.\"\"\"\n",
        "\n",
        "        # determine filename\n",
        "        f = filename\n",
        "\n",
        "        # load data\n",
        "        with open(f, 'r') as fid :\n",
        "            data = np.loadtxt(fid, delimiter=\",\", skiprows=header)\n",
        "\n",
        "        # separate features and labels\n",
        "        if predict_col is None :\n",
        "            self.X = data[:,:]\n",
        "            self.y = None\n",
        "        else :\n",
        "            if data.ndim > 1 :\n",
        "                self.X = np.delete(data, predict_col, axis=1)\n",
        "                self.y = data[:,predict_col]\n",
        "            else :\n",
        "                self.X = None\n",
        "                self.y = data[:]\n",
        "\n",
        "        # load feature and label names\n",
        "        if header != 0:\n",
        "            with open(f, 'r') as fid :\n",
        "                header = fid.readline().rstrip().split(\",\")\n",
        "\n",
        "            if predict_col is None :\n",
        "                self.Xnames = header[:]\n",
        "                self.yname = None\n",
        "            else :\n",
        "                if len(header) > 1 :\n",
        "                    self.Xnames = np.delete(header, predict_col)\n",
        "                    self.yname = header[predict_col]\n",
        "                else :\n",
        "                    self.Xnames = None\n",
        "                    self.yname = header[0]\n",
        "        else:\n",
        "            self.Xnames = None\n",
        "            self.yname = None\n",
        "\n",
        "\n",
        "# helper functions\n",
        "def load_data(filename, header=0, predict_col=-1) :\n",
        "    \"\"\"Load csv file into Data class.\"\"\"\n",
        "    data = Data()\n",
        "    data.load(filename, header=header, predict_col=predict_col)\n",
        "    return data"
      ],
      "metadata": {
        "id": "DVxef2sxOmVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the path to your own data directory\n",
        "### ========== TODO : START ========== ###\n",
        "titanic = load_data(\"/content/drive/My Drive/Academics/2023-2024/EC_ENGR_M146/HW3-code/data/titanic_train.csv\", header=1, predict_col=0)\n",
        "### ========== TODO : END ========== ###\n",
        "X = titanic.X; Xnames = titanic.Xnames\n",
        "y = titanic.y; yname = titanic.yname\n",
        "n,d = X.shape  # n = number of examples, d =  number of features"
      ],
      "metadata": {
        "id": "_Zcf4WVqJSpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error(clf, X, y, ntrials=100, test_size=0.2) :\n",
        "    \"\"\"\n",
        "    Computes the classifier error over a random split of the data,\n",
        "    averaged over ntrials runs.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf         -- classifier\n",
        "        X           -- numpy array of shape (n,d), features values\n",
        "        y           -- numpy array of shape (n,), target classes\n",
        "        ntrials     -- integer, number of trials\n",
        "        test_size   -- proportion of data used for evaluation\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        train_error -- float, training error\n",
        "        test_error  -- float, test error\n",
        "    \"\"\"\n",
        "\n",
        "    train_error = 0\n",
        "    test_error = 0\n",
        "\n",
        "    train_scores = []; test_scores = [];\n",
        "    for i in range(ntrials):\n",
        "        xtrain, xtest, ytrain, ytest = train_test_split (X,y, test_size = test_size, random_state = i)\n",
        "        clf.fit (xtrain, ytrain)\n",
        "\n",
        "        ypred = clf.predict (xtrain)\n",
        "        err = 1 - metrics.accuracy_score (ytrain, ypred, normalize = True)\n",
        "        train_scores.append (err)\n",
        "\n",
        "        ypred = clf.predict (xtest)\n",
        "        err = 1 - metrics.accuracy_score (ytest, ypred, normalize = True)\n",
        "        test_scores.append (err)\n",
        "\n",
        "    train_error =  np.mean (train_scores)\n",
        "    test_error = np.mean (test_scores)\n",
        "    return train_error, test_error\n"
      ],
      "metadata": {
        "id": "3Ta7XHRWQGNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 4(a): Implement the decision tree classifier and report the training error.\n",
        "print('Classifying using Decision Tree...')\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "error(clf, X, y)\n",
        "### ========== TODO : END ========== ###"
      ],
      "metadata": {
        "id": "W8-U3un5PjGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1db64f5-9607-44dc-fbea-bcf6b8e18ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying using Decision Tree...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.011528998242530775, 0.24104895104895108)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 4(b): Implement the random forest classifier and adjust the number of samples used in bootstrap sampling.\n",
        "print('Classifying using Random Forest...')\n",
        "max_samples_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "training_errors_list = []\n",
        "test_errors_list = []\n",
        "for max_samples in max_samples_list:\n",
        "  clf = RandomForestClassifier(criterion = 'entropy', random_state = 0, max_samples = max_samples)\n",
        "  training_error, test_error = error(clf, X, y)\n",
        "  training_errors_list.append(training_error)\n",
        "  test_errors_list.append(test_error)\n",
        "\n",
        "best_max_samples = max_samples_list[np.argmin(test_errors_list)]\n",
        "print(\"best max_samples: \", best_max_samples)\n",
        "### ========== TODO : END ========== ###"
      ],
      "metadata": {
        "id": "_x_PevK8Q4dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78ffef3-d402-4312-a11d-f31a524b7c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying using Random Forest...\n",
            "best max_samples:  0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"best max_samples training error: \", (training_errors_list[np.argmin(test_errors_list)]))\n",
        "print(\"best max_samples test error: \", np.min(test_errors_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bYphEej_Bz5",
        "outputId": "e321a284-72c4-45cc-efc9-93e8e279e4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best max_samples training error:  0.09427065026362039\n",
            "best max_samples test error:  0.1874825174825175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 4(c): Implement the random forest classifier and adjust the number of features for each decision tree.\n",
        "print('Classifying using Random Forest...')\n",
        "max_features_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "training_error_list = []\n",
        "test_error_list = []\n",
        "for max_features in max_features_list:\n",
        "  clf = RandomForestClassifier(criterion = 'entropy', random_state = 0, max_features = max_features, max_samples = best_max_samples)\n",
        "  training_error, test_error = error(clf, X, y)\n",
        "  training_error_list.append(training_error)\n",
        "  test_error_list.append(test_error)\n",
        "\n",
        "best_max_features = max_features_list[np.argmin(test_error_list)]\n",
        "print(\"best max_features: \", best_max_features)\n",
        "### ========== TODO : END ========== ###"
      ],
      "metadata": {
        "id": "ZFUyPTPwT53v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae11d458-ee99-4a10-c33c-853493ca7e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying using Random Forest...\n",
            "best max_features:  3\n",
            "best max_features training error:  0.09165202108963091\n",
            "best max_features test error:  0.18678321678321677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"best max_features training error: \", training_error_list[np.argmin(test_error_list)])\n",
        "print(\"best max_features test error: \", np.min(test_error_list))"
      ],
      "metadata": {
        "id": "ZSoAQ5QtBMYF",
        "outputId": "b5b051ef-c5d4-4d75-dc12-c30fb9380fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best max_features training error:  0.09481546572934976\n",
            "best max_features test error:  0.18678321678321677\n"
          ]
        }
      ]
    }
  ]
}